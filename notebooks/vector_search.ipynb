{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fikrifaizz/indo-sentiment-engine/blob/main/notebooks/vector_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nSq297-OfgsT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from peft import PeftModel, PeftConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: mps\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Model & LoRA Adapter...\n",
            "Mencoba memuat Base Model dari cache lokal...\n",
            "Merging LoRA weights into Base Model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(50000, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BASE_MODEL = \"indobenchmark/indobert-base-p1\"\n",
        "LORA_PATH = \"../models/indobert-lora-finetuned\"\n",
        "\n",
        "print(\"Loading Model & LoRA Adapter...\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(LORA_PATH)\n",
        "\n",
        "try:\n",
        "    print(\"Mencoba memuat Base Model dari cache lokal...\")\n",
        "    base_model = AutoModel.from_pretrained(BASE_MODEL, local_files_only=True)\n",
        "except Exception as e:\n",
        "    print(\"Gagal load lokal, mencoba download ulang dari HuggingFace (Internet Required)...\")\n",
        "    base_model = AutoModel.from_pretrained(BASE_MODEL, local_files_only=False)\n",
        "\n",
        "peft_model = PeftModel.from_pretrained(base_model, LORA_PATH)\n",
        "\n",
        "print(\"Merging LoRA weights into Base Model...\")\n",
        "model = peft_model.merge_and_unload()\n",
        "\n",
        "model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensi Vektor: 768 (Harus 768)\n"
          ]
        }
      ],
      "source": [
        "def get_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    \n",
        "    token_embeddings = outputs.last_hidden_state\n",
        "    \n",
        "    attention_mask = inputs['attention_mask'].unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(token_embeddings * attention_mask, 1)\n",
        "    sum_mask = torch.clamp(attention_mask.sum(1), min=1e-9)\n",
        "    \n",
        "    embedding = sum_embeddings / sum_mask \n",
        "    \n",
        "    return embedding.cpu().numpy()[0].tolist()\n",
        "\n",
        "# Tes fungsi\n",
        "dummy_vec = get_embedding(\"Tes barang bagus\")\n",
        "print(f\"Dimensi Vektor: {len(dummy_vec)} (Harus 768)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChromaDB Collection 'lazada_reviews' siap!\n"
          ]
        }
      ],
      "source": [
        "DB_PATH = \"../data/chroma_db\"\n",
        "client = chromadb.PersistentClient(path=DB_PATH)\n",
        "\n",
        "collection_name = \"lazada_reviews\"\n",
        "try:\n",
        "    client.delete_collection(name=collection_name)\n",
        "    print(\"Koleksi lama dihapus.\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "collection = client.create_collection(\n",
        "    name=collection_name,\n",
        "    metadata={\"hnsw:space\": \"cosine\"} # Kita pakai Cosine Similarity\n",
        ")\n",
        "print(f\"ChromaDB Collection '{collection_name}' siap!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sedang meng-embed 1000 review ke ChromaDB...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e359e06858b45a49aae77049cb201fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indexing Selesai!\n"
          ]
        }
      ],
      "source": [
        "df_test = pd.read_parquet(\"../data/final/test.parquet\")\n",
        "df_sample = df_test.head(1000).copy().reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nSedang meng-embed {len(df_sample)} review ke ChromaDB...\")\n",
        "\n",
        "batch_size = 32\n",
        "total_batches = len(df_sample) // batch_size + 1\n",
        "\n",
        "for i in tqdm(range(0, len(df_sample), batch_size)):\n",
        "    batch = df_sample.iloc[i : i+batch_size]\n",
        "    \n",
        "    # Generate Embeddings\n",
        "    ids = [str(x) for x in batch.index.tolist()]\n",
        "    documents = batch['clean_text'].tolist()\n",
        "    metadatas = [{\"rating\": int(r), \"label\": int(l)} for r, l in zip(batch['rating'], batch['label'])]\n",
        "    \n",
        "    embeddings = [get_embedding(doc) for doc in documents]\n",
        "    \n",
        "    # Masukkan ke ChromaDB\n",
        "    collection.add(\n",
        "        ids=ids,\n",
        "        embeddings=embeddings,\n",
        "        documents=documents,\n",
        "        metadatas=metadatas\n",
        "    )\n",
        "\n",
        "print(\"Indexing Selesai!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query: 'pengiriman lama banget sampe seminggu'\n",
            "   [1] pengirimannya lama banget\n",
            "       Rating: 5 | Sentimen: Positif\n",
            "       DIST: 0.1222\n",
            "   [2] barangnya alhamdulillah bagus cuma lama banget pengirimanya\n",
            "       Rating: 2 | Sentimen: Negatif\n",
            "       DIST: 0.1702\n",
            "   [3] pengiriman cepat banget pesan malem besoknya dikirim mksh lazada\n",
            "       Rating: 5 | Sentimen: Positif\n",
            "       DIST: 0.2338\n",
            "\n",
            "Query: 'barang pecah pas sampe'\n",
            "   [1] barang minggu langsung rusak\n",
            "       Rating: 1 | Sentimen: Negatif\n",
            "       DIST: 0.1879\n",
            "   [2] barang fah sampai berfungsi\n",
            "       Rating: 5 | Sentimen: Positif\n",
            "       DIST: 0.2153\n",
            "   [3] cepat sampai barang ori\n",
            "       Rating: 5 | Sentimen: Positif\n",
            "       DIST: 0.2271\n",
            "\n",
            "Query: 'kurir ramah sopan'\n",
            "   [1] pengiriman sangat cepat\n",
            "       Rating: 5 | Sentimen: Positif\n",
            "       DIST: 0.2533\n",
            "   [2] pengiriman cepat pengemasan rapi\n",
            "       Rating: 5 | Sentimen: Positif\n",
            "       DIST: 0.2611\n",
            "   [3] barang bagus sesuai deskripsi kurir ramah mudah an awet\n",
            "       Rating: 5 | Sentimen: Positif\n",
            "       DIST: 0.2620\n"
          ]
        }
      ],
      "source": [
        "def search_reviews(query, top_k=3):\n",
        "    print(f\"\\nQuery: '{query}'\")\n",
        "    \n",
        "    # Ubah query user jadi vektor\n",
        "    query_vec = get_embedding(query)\n",
        "    \n",
        "    # Cari tetangga terdekat di ChromaDB\n",
        "    results = collection.query(\n",
        "        query_embeddings=[query_vec],\n",
        "        n_results=top_k\n",
        "    )\n",
        "    \n",
        "    # Tampilkan hasil\n",
        "    for i in range(top_k):\n",
        "        review = results['documents'][0][i]\n",
        "        meta = results['metadatas'][0][i]\n",
        "        score = results['distances'][0][i] # Cosine Distance (Makin kecil makin mirip)\n",
        "        \n",
        "        label_map = {0: 'Negatif', 1: 'Netral', 2: 'Positif'}\n",
        "        print(f\"   [{i+1}] {review}\")\n",
        "        print(f\"       Rating: {meta['rating']} | Sentimen: {label_map[meta['label']]}\")\n",
        "        print(f\"       DIST: {score:.4f}\")\n",
        "\n",
        "# Coba cari sesuatu yang spesifik\n",
        "search_reviews(\"pengiriman lama banget sampe seminggu\")\n",
        "search_reviews(\"barang pecah pas sampe\")\n",
        "search_reviews(\"kurir ramah sopan\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP6AIgoKSjNPZDXHk2hngzo",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
